<!DOCTYPE html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"><!--<![endif]-->
<head>
        <meta charset="UTF-8">
    <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
    <meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1">
    <title>RL note #1 &#8211; </title>
    <meta name="description" content="blog">
    <meta name="keywords" content="Reinforcement Learning">
    <!-- Twitter Cards -->
    <meta name="twitter:card" content="summary">
    <meta name="twitter:image" content="/assets/img/logo.png">
    <meta name="twitter:title" content="RL note #1">
    <meta name="twitter:description" content="Machine Learning">
    
    <!-- Open Graph -->
    <meta property="og:locale" content="en_US">
    <meta property="og:type" content="article">
    <meta property="og:title" content="RL note #1">
    <meta property="og:description" content="Machine Learning">
    <meta property="og:url" content="/posts/RL-note-1">
    <meta property="og:site_name" content="">
    <meta property="og:image" content="/assets/img/logo.png">
    
    
    
    <link rel="canonical" href="/posts/RL-note-1">
    <link href="/feed.xml" type="application/atom+xml" rel="alternate" title=" Feed">
    <!-- Handheld -->
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/main.css">
    <!-- JS -->
    <script src="/assets/js/modernizr-3.3.1.custom.min.js"></script>
    <!-- Favicons -->
    <link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png">
    <link rel="shortcut icon" type="image/png" href="/favicon.png" />
    <link rel="shortcut icon" href="/favicon.ico" />
    <!-- Background Image -->
    
    
    
    <style type="text/css">body {background-image:url(/assets/img/placeholder-big.jpg);  background-repeat: no-repeat; background-size: cover; }</style>
    
    <!-- Post Feature Image -->
    

    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
    equationNumbers: {
      autoNumber: "AMS"
    }
},
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$', '$$'] ],
    processEscapes: true,
  }
});
MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
  alert("Math Processing Error: "+message[1]);
});
MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
  alert("Math Processing Error: "+message[1]);
});
</script>
<script type="text/javascript" async
src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

</head>
<body>
    	<nav id="dl-menu" class="dl-menuwrapper" role="navigation">
		<button class="dl-trigger">Open Menu</button>
		<ul class="dl-menu">
			<li><a href="/">Home</a></li>
			<li><a href="/about/en">About</a></li>
			<li><a href="/projects">Projects</a></li>
			<li><a href="/posts/">Posts</a></li>
		</ul><!-- /.dl-menu -->
	</nav><!-- /.dl-menuwrapper -->

    <!-- Header -->
    <header class="header" role="banner">
        <div class="wrapper animated fadeIn">
            <button class="btn zoombtn" onclick="history.back()"><i class="fa fa-chevron-left"></i></button>
            <div class="content">
                <div class="page-title ">
                    <h1>RL note #1</h1>
                    <h4>31 Dec 2017</h4>
                    
                </div>
                <h1 id="강화학습">강화학습</h1>

<hr />

<h2 id="강화학습이란">강화학습이란</h2>
<h3 id="개요">개요</h3>
<ul>
  <li>시행착오를 통하여 학습하는 알고리즘</li>
  <li>실제상황
    <ul>
      <li>상황이 주어짐 (자전거를 타는 상황)</li>
      <li>에이전트가 행동 (오른쪽으로 핸들 돌리기)</li>
      <li>환경이 보상 (넘어짐 / 안넘어짐)</li>
    </ul>
  </li>
</ul>

<h3 id="적용가능한-문제들">적용가능한 문제들</h3>
<ul>
  <li>경로 찾기, 스케줄링</li>
  <li>미로찾기, Frozen Lake, TSP …</li>
</ul>

<hr />

<h2 id="기본-모델">기본 모델</h2>
<h3 id="순차적-행동-결정-문제">순차적 행동 결정 문제</h3>
<ul>
  <li>순차적으로 행동을 결정해야하는 문제들</li>
  <li>5 * 5 격자공간에서 이동 최단거리를 탐색 문제로 가정
( (0, 0)에서 시작, (4, 4)에서 종료 )</li>
</ul>

<h3 id="순차적-행동-결정-문제의-구성-요소">순차적 행동 결정 문제의 구성 요소</h3>
<ul>
  <li>상태(state) : &lt;/tab&gt;현재 내가 어디에 있는지</li>
  <li>행동(action) : 어디로 이동할지</li>
  <li>보상(reward) : 행동 했을 때 좋은 행동인지 안 좋은 행동인지</li>
  <li>정책(policy) : 각각의 상황에서 어디로 이동할 지에 대한 표지판</li>
</ul>

<hr />

<h2 id="mdp와-벨만-방정식">MDP와 벨만 방정식</h2>
<h3 id="mdpmarkov-decision-process">MDP(Markov Decision Process)</h3>
<ul>
  <li>순차적 행동결정 문제를 수학적 정의하여 프로세스를 설명</li>
  <li>상태 / 행동 / 보상 / 상태 변환 확률 / 정책 으로 구성</li>
</ul>

<h3 id="mdp-구성-요소">MDP 구성 요소</h3>
<ul>
  <li>상태(S) = (1, 1) : (1, 1)지점에 존재</li>
  <li>행동(A) = (1,0,0,0) : 위로 움직임</li>
  <li>보상함수(R)
    <ul>
      <li>$R = E[R|S, A]$</li>
      <li>(1,1) 지점에서 위로 움직였을 때 받을 보상(E = 기대)</li>
    </ul>
  </li>
  <li>상태 변환 확률(P)
    <ul>
      <li>$P^{ss’}_{a} = P[S = s’|S = s, A = a]$ : (1, 1) 지점에서 움직일지 말지</li>
    </ul>
  </li>
  <li>정책(π)
    <ul>
      <li>$π(a|s) = P[A = a|S = s]$ : (1,1) 위치에서 어디로 이동해야 가장 좋을지</li>
    </ul>
  </li>
</ul>

<h3 id="mdp-외-문제를-풀기위해-필요한-개념">MDP 외 문제를 풀기위해 필요한 개념</h3>
<ul>
  <li>감가율( γ )</li>
  <li>모든 보상은 감가율이 계산되어 가치로 환산됨</li>
  <li>
    <p>감가율을 고려한 미래보상의 현재 가치(V) = $γ^{𝒌−𝟏} 𝑹_𝒌$</p>
  </li>
  <li>반환값 (G)
    <ul>
      <li>감가율이 계산된 보삼들의 합</li>
      <li>$𝑹_𝟏  + γ𝑹_𝟐 + γ^𝟐 𝑹_𝟑 + … + γ^{𝒏−𝟏} 𝑹_𝒏$</li>
    </ul>
  </li>
  <li>가치함수(V)</li>
  <li>각각의 노드들이 가지고 있는 가치</li>
  <li>이후에 받을 감가율이 계산된 보상들의 합</li>
  <li>
    <p>$V =  E[G | S = s]$ <br />
  =  $E[𝑹_𝟏  + γ𝑹_𝟐 + γ^𝟐 𝑹_𝟑   + … + γ^{𝒏−𝟏} 𝑹_𝒏]$<br />
  =  $E[𝑹_𝟏 + γV’]$</p>
  </li>
  <li>Q함수
    <ul>
      <li>행동 가치함수 (방향이 정해진 가치함수)</li>
      <li>한 상태에서 네 방향으로의 진행이 가능하기 때문에 가치함수를 구하려면 네 방향의 보상과 가치함수를 고려해야 함</li>
      <li>오른쪽의 Q함수 = (오른쪽의 보상 + γ * 오른쪽 노드의 가치함수)</li>
      <li>오른쪽의 Q함수 = (오른쪽의 보상 + γ * 오른쪽 노드의 다음행동 Q함수)</li>
      <li>계산 가능 형태의 가치함수(V)<br />
= 각 방향의 정책 * 각 방향의 Q함수 <br />
=  $\sum_{a\in A} π(a|s) * q(s, a)$</li>
    </ul>
  </li>
</ul>

<h3 id="벨만-방정식">벨만 방정식</h3>
<ul>
  <li>가치를 계산하는 방정식</li>
</ul>

<h3 id="벨만-기대-방정식">벨만 기대 방정식</h3>
<ul>
  <li>정책에 따라서 가치를 판단 ( 정책은 항상 고정되어 있고 정책 발전시에만 변경됨 )</li>
  <li>가치함수 = 각 방향의 정책 * 각 방향의 (보상 + 감가율 * 다음 상태의 가치함수)</li>
  <li>$𝑽_π (s)$ = $𝑬_π[R + γ𝑽_π (𝑺_{𝒕+𝟏}) | 𝑺_𝒕 = s]$ <br />
= $\sum_{𝒂\in 𝑨}π(a|s) * (𝑹_{𝒕+𝟏}+γ𝒗_π (𝒔^′))$</li>
</ul>

<h3 id="벨만-최적-방정식">벨만 최적 방정식</h3>
<ul>
  <li>가장 높은 Q함수를 가진 노드만을 선택하여 가치함수 계산 ( 정책과 상관없이 )</li>
  <li>가치함수 = 보상 + 감가율 * 최고 가치를 가진 방향의 가치함수</li>
  <li>$\prod^{*}(s,a) =
\begin{cases}
1\ if\ a = argmax_{a\in A}q^*(s,a)
\\ 0\ otherwise
\end{cases}$</li>
  <li>$v^*(s)	= maxE[R + γ𝑽_π (𝑺_{𝒕+𝟏}) | 𝑺_𝒕 = s ]$</li>
  <li>$q^{*}(s) = E[R + γ max q^* (𝑺_{𝒕+𝟏}, a’) | 𝑺_𝒕 = s, 𝑨_𝒕=𝒂 ]$</li>
</ul>

                <div class="entry-meta">
                <br>
<hr>

<div style="width:100%">
<div style="width:10%;float:left;">
    <span style="color:#999999;">출처</span>
</div>
<div style="width:90%;float:left;">

    <span style="color:#999999;">이웅원 외 4명 저 '파이썬과 케라스로 배우는 강화학습'</span><br>

</div>
<span style="color:black;"></span>
<span class="refer-tags">
</span>
</div>

<span class="entry-tags"><a href="/tags/#Reinforcement Learning" title="Pages tagged Reinforcement Learning" class="tag"><span class="term">Reinforcement Learning</span></a></span>
<div style="clear:both"></div>

                </div>
            </div>
        </div>
        <!-- <section id="disqus_thread" class="animated fadeInUp"></section><!-- /#disqus_thread --> -->
    </header>
        <!-- JS -->
    <script src="/assets/js/jquery-1.12.0.min.js"></script>
    <script src="/assets/js/jquery.dlmenu.min.js"></script>
    <script src="/assets/js/jquery.goup.min.js"></script>
    <script src="/assets/js/jquery.magnific-popup.min.js"></script>
    <script src="/assets/js/jquery.fitvid.min.js"></script>
    <script src="/assets/js/scripts.js"></script>
    
    
    <!-- MathJax -->
    <script async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
</body>
</html>
